{"cells":[{"cell_type":"code","source":["!pip -q install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKzo6BCblhz6","executionInfo":{"status":"ok","timestamp":1717533686122,"user_tz":-600,"elapsed":20890,"user":{"displayName":"Trung Nguyễn Vũ","userId":"02158753298940026143"}},"outputId":"f126bff1-8d00-4790-c82d-b647feeffdb3"},"id":"LKzo6BCblhz6","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"og_IWQUmlkAg","executionInfo":{"status":"ok","timestamp":1717533719072,"user_tz":-600,"elapsed":32954,"user":{"displayName":"Trung Nguyễn Vũ","userId":"02158753298940026143"}},"outputId":"b0923360-2823-4b1c-920e-30b6385020f5"},"id":"og_IWQUmlkAg","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"id":"70622dad-8ab5-40f2-9226-70d2f83cbf76","metadata":{"tags":[],"id":"70622dad-8ab5-40f2-9226-70d2f83cbf76","executionInfo":{"status":"ok","timestamp":1717533722291,"user_tz":-600,"elapsed":3225,"user":{"displayName":"Trung Nguyễn Vũ","userId":"02158753298940026143"}}},"outputs":[],"source":["import requests\n","import http,json\n","import openai\n","import os\n","import pandas as pd\n","from datetime import datetime\n","\n","# import local library\n","import sys\n","# sys.path.append(r'/content/drive/Othercomputers/My Laptop/NIT6001/CMG_prog_v2')\n","sys.path.append(os.path.abspath('/content/drive/Othercomputers/My Laptop/NIT6001/CMG_prog_v2'))\n","from GPTCall import ask_chatgpt\n","from SaveExcel_v2 import update_sheet_preserving_format, update_list_sheets_preserving_format"]},{"cell_type":"code","execution_count":4,"id":"8455b064-90e0-4580-9d21-018b1b81b2e4","metadata":{"tags":[],"id":"8455b064-90e0-4580-9d21-018b1b81b2e4","executionInfo":{"status":"ok","timestamp":1717533735093,"user_tz":-600,"elapsed":4,"user":{"displayName":"Trung Nguyễn Vũ","userId":"02158753298940026143"}}},"outputs":[],"source":["mypath = r\"/content/drive/Othercomputers/My Laptop/NIT6001/CMG_dataset\"\n","myfile = r\"/MSDManual/Cognitive Map Graph Processing v4 2024.03.14.xlsx\"\n","process_knowledge_filename = r\"/MSDManual/CMG_article_process_knowledge.xlsx\"\n","\n","# Use os.path.join to create the full paths\n","process_knowledge_file_fullpath = os.path.join(mypath, process_knowledge_filename.lstrip('/'))\n","myexcelfile = os.path.join(mypath, myfile.lstrip('/'))"]},{"cell_type":"code","execution_count":5,"id":"71df6b06-c6d3-4b78-a627-5a8a0f487189","metadata":{"tags":[],"id":"71df6b06-c6d3-4b78-a627-5a8a0f487189","executionInfo":{"status":"ok","timestamp":1717533735094,"user_tz":-600,"elapsed":3,"user":{"displayName":"Trung Nguyễn Vũ","userId":"02158753298940026143"}}},"outputs":[],"source":["import time\n","def keyfunction_readme():\n","    i=i\n","    # key function steps\n","    #-------------------------------------\n","\n","    # 1.  In mypath folder, there is an excel file called Cognitive Map Graph Processing v3 2024.02.14.xlsx\n","    # 2.  The excel file hastwo sheets, one are paragraphs, and one are cognitive map graph sentences\n","        # Sheet name: paragraphs\n","        #Columns: ['ID', 'Paragraph text', 'url', 'category labels', 'summarised key points in simple sentences', 'processing user', 'processing date']\n","\n","        #Sheet name: sentences\n","        #Columns: ['ID', 'paragraph ID', 'CMG Auto with GPT', 'CMG by Human Expert', 'Justification of the correction', 'processing user', 'processing date', 'correction user', 'corrction date']\n","\n","    # 3. Read the original text to a dataframe called df, run through it row by row, call ChatGPT API,\n","    #     use the following myprompt to summarise the key points of the text:\n","    #     myprompt=\"1) Summarise the key point, or information/knowledge, of the following text,\n","    #               2) use simple structrued setnecnes;  3) each sentence should be self contained, avoid using propositions\n","    #               to refer to entities in ealrier sentences; 4) response in format of  Key Points =  'the key points' \"\n","    # 4. Parse the ChatGPT response to extract the keypoints, and update the keypoints in col4 of the dataframe df\n","    # 5. For each row in col4, ask chatGPT API to convert the sentences into  head, relation, tail structure. For example,\n","    #        Acute kidney injury is a rapid decrease in renal function over days to weeks. will be separated into:\n","    #        Acute kidney injury, is, a rapid decrease in renal function (duration: over days to weeks).\n","    #     Here we use () to enclose properties of the head, tail or relation. Multiple properties can be separated with comma.\n","    # 6. Note that a sentence may not have a tail, which can be represented with a -. For example,\n","    #       Acute kidney injury can be fatal.   can be converted as\n","    #       Acute kidney injury, can be fatal, -.\n","    # 7. For a sentence with a sub clause, use [] to enclose the main sentence and the sub clause. Use []-(connecting word)-[]. for the converted sentence.\n","    #      for example,  Tom had AKI when he was 50.  will be converted as\n","    #                   [Tom, had AKI, -]-(when)-[Tom, was 50, -]\n","    #      note the relationship needs to be meaningful. is, have, get are too short to represent the meaning of the relation.\n","    # 8. Resonse will be in format of  FCM scripts= ' ****'\n","    # 9. Extract FCM scripts from the response, and write to col5 of df\n","\n","def main():\n","    print (\"main function started \\n--------------------\")\n","    time_started=time.time()\n","\n","    # myexcelfile=mypath+'Cognitive Map Graph Processing v4 2024.03.14.xlsx'\n","    #check_excelfile_info(myexcelfile)\n","\n","    df_sentences = pd.read_excel(myexcelfile, sheet_name='sentences')\n","    row_start=0;       row_end=0 # end is 0 means to the end\n","    convertsentence_toCMG(df_sentences,row_start, row_end )\n","\n","    update_sheet_preserving_format(myexcelfile, 'sentences', df_sentences)\n","\n","    time_finished=time.time()\n","    timeused=time_finished-time_started\n","    print(\"Time used=\", round(timeused,2))\n","\n","\n","def check_excelfile_info(myexcelfile):\n","# check the sheet names and columns in the excel file\n","     # Iterate through all sheets\n","    print(myexcelfile)\n","    xls = pd.ExcelFile(myexcelfile)\n","\n","    for sheet_name in xls.sheet_names:\n","        # Read each sheet\n","        df = pd.read_excel(xls, sheet_name)\n","\n","        # Print the sheet name and its columns\n","        print(f\"Sheet name: {sheet_name}\")\n","        print(\"Columns:\", df.columns.tolist())\n","\n","\n","\n","def convertCMG_prompt():\n","    # changed to read prompts from excel file\n","\n","    df = pd.read_excel(process_knowledge_file_fullpath, sheet_name=\"knowledge\", engine='openpyxl')\n","    filtered_df = df[(df['knowledge_area'] == \"step3_convert_sentence_to_cognitive_map_graph\") ]\n","    if filtered_df.empty:\n","        myprompt=\"Could not read the knowledge on step3_convert_sentence_to_cognitive_map_graph.\\n\"\n","    else:\n","        myprompt = '\\n'.join(filtered_df['knowledge'].astype(str))\n","    return myprompt +\"\\n Here is the sentence:\"\n","\n","\n","def convertsentence_toCMG(df_sentences,row_start, row_end ):\n","    print (\"convertsentence_toCMG function started \\n--------------------\")\n","    myprompt=convertCMG_prompt()\n","    if row_end == 0:   row_end = df_sentences.index[-1]\n","\n","    for index in range(row_start, row_end + 1):  # +1 because the range end is exclusive\n","        if index < len(df_sentences) : # Check to ensure index is within DataFrame bounds\n","            if df_sentences.at[index, 'processed'] !='Yes':\n","                sentence_text = df_sentences.at[index, 'Sentence text']\n","                response_text = ask_chatgpt(myprompt, sentence_text)\n","                df_sentences.at[index, 'CMG Auto with GPT'] = response_text\n","                df_sentences.at[index, 'processed'] = 'Yes'\n","\n","        else:\n","            break\n","\n","    return df_sentences"]},{"cell_type":"code","execution_count":6,"id":"03590912-2120-404f-aad9-9ac19c84ad1e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03590912-2120-404f-aad9-9ac19c84ad1e","executionInfo":{"status":"ok","timestamp":1717533750083,"user_tz":-600,"elapsed":13489,"user":{"displayName":"Trung Nguyễn Vũ","userId":"02158753298940026143"}},"outputId":"8720dfb3-ea68-450b-bc59-5d9e4dc9e03b"},"outputs":[{"output_type":"stream","name":"stdout","text":["main function started \n","--------------------\n","convertsentence_toCMG function started \n","--------------------\n","Time used= 13.4\n"]}],"source":["main()"]},{"cell_type":"code","source":["# v1\n","import openpyxl\n","import pandas as pd\n","\n","# Load the Excel file\n","file_path = myexcelfile\n","sheet_name = \"sentences\"\n","\n","# Read the specified columns from the sheet\n","df = pd.read_excel(file_path, sheet_name=sheet_name, usecols=[\"CMG Auto with GPT\", \"Paragraph ID\"])\n","\n","# Create a list to hold the new rows for the new sheet\n","new_rows = []\n","\n","# Iterate through each row in the dataframe\n","for index, row in df.iterrows():\n","    cmg_text = row[\"CMG Auto with GPT\"]\n","    paragraph_id = row[\"Paragraph ID\"]\n","\n","    # Split the text by empty lines and remove empty entries\n","    sentences = [sentence.strip() for sentence in cmg_text.split('\\n\\n') if sentence.strip()]\n","\n","    # Create new rows for each split sentence\n","    for sentence_id, sentence in enumerate(sentences, start=1):\n","        new_rows.append({\n","            \"CMG Auto with GPT single line\": sentence,\n","            \"Paragraph ID\": paragraph_id,\n","            \"Sentence ID\": sentence_id\n","        })\n","\n","# Create a new dataframe from the new rows\n","new_df = pd.DataFrame(new_rows)\n","\n","# Write the new dataframe to the \"sentences2\" sheet in the same Excel file\n","with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n","    new_df.to_excel(writer, sheet_name=\"sentences2\", index=False)\n","\n","print(\"Processing complete.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZiybnPRKIXz","executionInfo":{"status":"ok","timestamp":1717525632994,"user_tz":-600,"elapsed":3179,"user":{"displayName":"Trung Nguyễn Vũ","userId":"02158753298940026143"}},"outputId":"b9316987-2190-4cd4-aaaf-9f2147fa3954"},"id":"7ZiybnPRKIXz","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing complete.\n"]}]},{"cell_type":"code","source":["# v2\n","import openpyxl\n","import pandas as pd\n","\n","# Load the Excel file\n","file_path = myexcelfile\n","sheet_name = \"sentences\"\n","\n","# Read the specified columns from the sheet\n","df = pd.read_excel(file_path, sheet_name=sheet_name, usecols=[\"CMG Auto with GPT\", \"Paragraph ID\"])\n","\n","# Check if the \"sentences2\" sheet exists\n","book = openpyxl.load_workbook(file_path)\n","if \"sentences2\" in book.sheetnames:\n","    # Load the existing \"sentences2\" sheet\n","    existing_df = pd.read_excel(file_path, sheet_name=\"sentences2\")\n","else:\n","    # Create an empty DataFrame if the sheet doesn't exist\n","    existing_df = pd.DataFrame(columns=[\n","        \"CMG Auto with GPT single line\",\n","        \"Paragraph ID\",\n","        \"Sentence ID\",\n","        \"Processed\",\n","        \"Justification of the correction\",\n","        \"CMG by Human Expert\"\n","    ])\n","\n","# Create a list to hold the new rows for the new sheet\n","new_rows = []\n","\n","# Iterate through each row in the dataframe\n","for index, row in df.iterrows():\n","    cmg_text = row[\"CMG Auto with GPT\"]\n","    paragraph_id = row[\"Paragraph ID\"]\n","\n","    # Split the text by empty lines and remove empty entries\n","    sentences = [sentence.strip() for sentence in cmg_text.split('\\n\\n') if sentence.strip()]\n","\n","    # Create new rows for each split sentence\n","    for sentence_id, sentence in enumerate(sentences, start=1):\n","        new_row = {\n","            \"CMG Auto with GPT single line\": sentence,\n","            \"Paragraph ID\": paragraph_id,\n","            \"Sentence ID\": sentence_id,\n","            \"Processed\": \"No\",  # Set default processed value to \"No\"\n","            \"Justification of the correction\": \"\",  # Default empty value\n","            \"CMG by Human Expert\": \"\"  # Default empty value\n","        }\n","\n","        # Check if the existing row has the same Paragraph ID and Sentence ID and if it is marked as processed\n","        if not existing_df.empty:\n","            existing_row = existing_df[(existing_df[\"Paragraph ID\"] == paragraph_id) & (existing_df[\"Sentence ID\"] == sentence_id)]\n","            if not existing_row.empty and existing_row[\"Processed\"].values[0] == \"Yes\":\n","                # If the existing row is marked as processed, retain the existing row's values\n","                new_row[\"Processed\"] = \"Yes\"\n","                new_row[\"Justification of the correction\"] = existing_row[\"Justification of the correction\"].values[0]\n","                new_row[\"CMG by Human Expert\"] = existing_row[\"CMG by Human Expert\"].values[0]\n","            elif not existing_row.empty:\n","                # If the existing row is not marked as processed, retain existing \"Justification of the correction\" and \"CMG by Human Expert\" values\n","                new_row[\"Justification of the correction\"] = existing_row[\"Justification of the correction\"].values[0]\n","                new_row[\"CMG by Human Expert\"] = existing_row[\"CMG by Human Expert\"].values[0]\n","\n","        new_rows.append(new_row)\n","\n","# Create a new dataframe from the new rows\n","new_df = pd.DataFrame(new_rows)\n","\n","# Combine with existing dataframe to ensure we retain all \"Processed\" rows without duplication\n","if not existing_df.empty:\n","    updated_df = pd.concat([\n","        existing_df[~existing_df[\"Paragraph ID\"].isin(new_df[\"Paragraph ID\"])],\n","        new_df\n","    ], ignore_index=True)\n","else:\n","    updated_df = new_df\n","\n","# Write the updated dataframe to the \"sentences2\" sheet in the same Excel file\n","with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n","    updated_df.to_excel(writer, sheet_name=\"sentences2\", index=False)\n","\n","print(\"Processing complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fKYK7N1MR8ax","executionInfo":{"status":"ok","timestamp":1717527105758,"user_tz":-600,"elapsed":6070,"user":{"displayName":"Trung Nguyễn Vũ","userId":"02158753298940026143"}},"outputId":"8180469c-d178-4552-822f-46fd1c4792b9"},"id":"fKYK7N1MR8ax","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing complete.\n"]}]},{"cell_type":"code","source":["# v3\n","import openpyxl\n","import pandas as pd\n","\n","# Load the Excel file\n","file_path = myexcelfile\n","sheet_name = \"sentences\"\n","\n","# Read the specified columns from the sheet\n","df = pd.read_excel(file_path, sheet_name=sheet_name, usecols=[\"CMG Auto with GPT\", \"Paragraph ID\"])\n","\n","# Check if the \"sentences2\" sheet exists\n","book = openpyxl.load_workbook(file_path)\n","if \"sentences2\" in book.sheetnames:\n","    # Load the existing \"sentences2\" sheet\n","    existing_df = pd.read_excel(file_path, sheet_name=\"sentences2\")\n","else:\n","    # Create an empty DataFrame if the sheet doesn't exist\n","    existing_df = pd.DataFrame(columns=[\n","        \"CMG Auto with GPT single line\",\n","        \"Paragraph ID\",\n","        \"Sentence ID\",\n","        \"Processed\",\n","        \"Justification of the correction\",\n","        \"CMG by Human Expert\"\n","    ])\n","\n","# Create a list to hold the new rows for the new sheet\n","new_rows = []\n","\n","# Iterate through each row in the dataframe\n","for index, row in df.iterrows():\n","    cmg_text = row[\"CMG Auto with GPT\"]\n","    paragraph_id = row[\"Paragraph ID\"]\n","\n","    # Split the text by empty lines and remove empty entries\n","    sentences = [sentence.strip() for sentence in cmg_text.split('\\n\\n') if sentence.strip()]\n","\n","    # Create new rows for each split sentence\n","    for sentence_id, sentence in enumerate(sentences, start=1):\n","        new_row = {\n","            \"CMG Auto with GPT single line\": sentence,\n","            \"Paragraph ID\": paragraph_id,\n","            \"Sentence ID\": sentence_id,\n","            \"Processed\": \"No\",  # Set default processed value to \"No\"\n","            \"Justification of the correction\": \"\",  # Default empty value\n","            \"CMG by Human Expert\": \"\"  # Default empty value\n","        }\n","\n","        # Check if the existing row has the same Paragraph ID and Sentence ID and if it is marked as processed\n","        if not existing_df.empty:\n","            existing_row = existing_df[(existing_df[\"Paragraph ID\"] == paragraph_id) & (existing_df[\"Sentence ID\"] == sentence_id)]\n","            if not existing_row.empty and existing_row[\"Processed\"].values[0] == \"Yes\":\n","                # If the existing row is marked as processed, retain the existing row's values\n","                new_row[\"Processed\"] = \"Yes\"\n","                new_row[\"Justification of the correction\"] = existing_row[\"Justification of the correction\"].values[0]\n","                new_row[\"CMG by Human Expert\"] = existing_row[\"CMG by Human Expert\"].values[0]\n","\n","        new_rows.append(new_row)\n","\n","# Create a new dataframe from the new rows\n","new_df = pd.DataFrame(new_rows)\n","\n","# Combine with existing dataframe to ensure we retain all \"Processed\" rows without duplication\n","if not existing_df.empty:\n","    updated_df = pd.concat([\n","        existing_df[~existing_df[\"Paragraph ID\"].isin(new_df[\"Paragraph ID\"])],\n","        new_df\n","    ], ignore_index=True)\n","else:\n","    updated_df = new_df\n","\n","# Ensure \"Justification of the correction\" and \"CMG by Human Expert\" are emptied when \"Processed\" is \"No\"\n","updated_df.loc[updated_df[\"Processed\"] == \"No\", [\"Justification of the correction\", \"CMG by Human Expert\"]] = \"\"\n","\n","# Write the updated dataframe to the \"sentences2\" sheet in the same Excel file\n","with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n","    updated_df.to_excel(writer, sheet_name=\"sentences2\", index=False)\n","\n","print(\"Processing complete.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zWI6W92l49a","executionInfo":{"status":"ok","timestamp":1717533809917,"user_tz":-600,"elapsed":4788,"user":{"displayName":"Trung Nguyễn Vũ","userId":"02158753298940026143"}},"outputId":"0879cf55-74d1-4cb8-c124-828fa64d1328"},"id":"3zWI6W92l49a","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing complete.\n"]}]},{"cell_type":"code","source":["#!pip install gspread pandas gspread-dataframe\n","import gspread\n","import pandas as pd\n","from gspread_dataframe import get_as_dataframe, set_with_dataframe\n","from google.oauth2.service_account import Credentials\n","\n","# Path to your service account key file\n","creds_file = 'path/to/your/service-account-file.json'\n","\n","# Define the scope\n","scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n","\n","# Authenticate using the service account\n","creds = Credentials.from_service_account_file(creds_file, scopes=scope)\n","client = gspread.authorize(creds)\n","\n","# Open the Google Sheets file by name\n","spreadsheet = client.open(\"Cognitive Map Graph Processing v4 2024.03.14\")\n","\n","# Load the specific sheet into a DataFrame\n","sheet_name = \"sentences\"\n","sheet = spreadsheet.worksheet(sheet_name)\n","df = get_as_dataframe(sheet, evaluate_formulas=True)\n","\n","# Drop any completely empty rows that might have been read in\n","df.dropna(how='all', inplace=True)\n","\n","# Create a list to hold the new rows for the new sheet\n","new_rows = []\n","\n","# Iterate through each row in the dataframe\n","for index, row in df.iterrows():\n","    cmg_text = row[\"CMG Auto with GPT\"]\n","    paragraph_id = row[\"Paragraph ID\"]\n","\n","    # Split the text by empty lines and remove empty entries\n","    sentences = [sentence.strip() for sentence in cmg_text.split('\\n\\n') if sentence.strip()]\n","\n","    # Create new rows for each split sentence\n","    for sentence_id, sentence in enumerate(sentences, start=1):\n","        new_rows.append({\n","            \"CMG Auto with GPT single line\": sentence,\n","            \"Paragraph ID\": paragraph_id,\n","            \"Sentence ID\": sentence_id\n","        })\n","\n","# Create a new dataframe from the new rows\n","new_df = pd.DataFrame(new_rows)\n","\n","# Write the new dataframe to a new sheet \"sentences2\"\n","new_sheet_name = \"sentences2\"\n","try:\n","    spreadsheet.del_worksheet(spreadsheet.worksheet(new_sheet_name))\n","except gspread.exceptions.WorksheetNotFound:\n","    pass\n","new_sheet = spreadsheet.add_worksheet(title=new_sheet_name, rows=new_df.shape[0], cols=new_df.shape[1])\n","set_with_dataframe(new_sheet, new_df)\n","\n","print(\"Processing complete.\")\n"],"metadata":{"id":"dEZj3oLpSUoO"},"id":"dEZj3oLpSUoO","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python (NIT003)","language":"python","name":"nit003"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}